{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sexual-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from object.loss import CrossEntropyLabelSmooth, Entropy\n",
    "from object import network\n",
    "import os, sys\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recovered-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_copy(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr0'] = param_group['lr']\n",
    "    return optimizer\n",
    "\n",
    "def lr_scheduler(optimizer, iter_num, max_iter, gamma=10, power=0.75):\n",
    "    decay = (1 + gamma * iter_num / max_iter) ** (-power)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr0'] * decay\n",
    "        param_group['weight_decay'] = 1e-3\n",
    "        param_group['momentum'] = 0.9\n",
    "        param_group['nesterov'] = True\n",
    "    return optimizer\n",
    "\n",
    "class ImageList(Dataset):\n",
    "    def __init__(self, imgs_path, transform, mode='RGB'):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.imgs_path[idx].split(',')\n",
    "        img = Image.open(path).convert(self.mode)\n",
    "        return self.transform(img), int(label)\n",
    "    \n",
    "def train_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def test_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "def load_data(source_path, target_path, bsize):\n",
    "    dsets = {}\n",
    "    dloaders = {}\n",
    "\n",
    "    src_txt = open(source_path, 'r').readlines()\n",
    "    target_txt = open(target_path, 'r').readlines()\n",
    "\n",
    "    dsize = len(src_txt)\n",
    "    train_size = int(0.9 * dsize)\n",
    "\n",
    "    train_txt, val_txt = torch.utils.data.random_split(src_txt, [train_size, dsize - train_size])\n",
    "\n",
    "    dsets['source_train'] = ImageList(train_txt, transform=train_transform())\n",
    "    dloaders['source_train'] = DataLoader(dsets['source_train'], batch_size=bsize, shuffle=True, drop_last=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    dsets['source_val'] = ImageList(val_txt, transform=test_transform())\n",
    "    dloaders['source_val'] = DataLoader(dsets['source_val'], batch_size=bsize, shuffle=True, drop_last=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    dsets['target_train'] = ImageList(target_txt, transform=train_transform())\n",
    "    dloaders['target_train'] = DataLoader(dsets['target_train'], batch_size=bsize*2, shuffle=True, drop_last=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "    dsets['target_test'] = ImageList(target_txt, transform=test_transform())\n",
    "    dloaders['target_test'] = DataLoader(dsets['target_test'], batch_size=bsize*2, shuffle=True, drop_last=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return dsets, dloaders\n",
    "\n",
    "def cal_acc(loader, model):\n",
    "    model.eval()\n",
    "    pred, true = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.cuda()\n",
    "            output, _ = model.forward(x)\n",
    "            pred.append(output.float().cpu())\n",
    "            true.append(y.float())\n",
    "\n",
    "    pred, true = torch.cat(pred), torch.cat(true)\n",
    "    pred = nn.Softmax(dim=1)(pred)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    acc = (torch.squeeze(pred).float() == true).float().mean()\n",
    "    return acc.item()\n",
    "\n",
    "def source_train(dloaders, margs, sargs):\n",
    "    param_group = []\n",
    "    learning_rate = 1e-2\n",
    "\n",
    "    model = Model(margs, sargs)\n",
    "    best_model = Model(margs, sargs)\n",
    "\n",
    "    for k, v in model.F.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate*0.1}]\n",
    "    for k, v in model.B.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]\n",
    "    for k, v in model.C.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]\n",
    "    optimizer = optim.SGD(param_group)\n",
    "    optimizer = op_copy(optimizer)\n",
    "    \n",
    "    max_iter = 20 * len(dloaders['source_train'])\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for iter_num in range(max_iter):\n",
    "        total_loss = 0\n",
    "        total_length = 0\n",
    "        for i, (source_x, source_y) in enumerate(dloaders['source_train']):\n",
    "            lr_scheduler(optimizer, iter_num=iter_num, max_iter=max_iter)\n",
    "            source_x, source_y = source_x.cuda(), source_y.cuda()\n",
    "            \n",
    "            outputs, _ = model.forward(source_x)\n",
    "            loss = CrossEntropyLabelSmooth(num_classes=65, epsilon=0.1)(outputs, source_y)\n",
    "            \n",
    "            total_loss += len(source_x)*loss.item()\n",
    "            total_length += len(source_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print('Step: %02d/%02d, Training Loss: %.4f' % (i+1, len(dloaders['source_train']), total_loss / total_length), end='\\r')\n",
    "\n",
    "        acc_val = cal_acc(dloaders['source_val'], model)\n",
    "        model.train()\n",
    "        print('Iter: %03d/%03d, Valid Acc: %.2f%%' % (iter_num + 1, max_iter, 100*acc_val))\n",
    "\n",
    "        if acc_val > best_acc:\n",
    "            best_acc = acc_val\n",
    "            best_model.copy(model)\n",
    "\n",
    "    best_model.save(source=True)\n",
    "    \n",
    "def target_train(dloaders, model):\n",
    "    model.target_train_mode()\n",
    "    \n",
    "    for k, v in model.C.named_parameters():\n",
    "        v.requires_grad = False\n",
    "    \n",
    "    param_group = []\n",
    "    learning_rate = 1e-2\n",
    "    for k, v in model.F.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate*0.1}]\n",
    "    for k, v in model.B.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]\n",
    "        \n",
    "    optimizer = optim.SGD(param_group)\n",
    "    optimizer = op_copy(optimizer)\n",
    "    \n",
    "    max_iter = 20\n",
    "    \n",
    "    for iter_num in range(max_iter):\n",
    "        for i, (target_x, target_y) in enumerate(dloaders['target_train']):\n",
    "            lr_scheduler(optimizer, iter_num=iter_num, max_iter=max_iter)\n",
    "            target_x, target_y = target_x.cuda(), target_y.cuda()\n",
    "\n",
    "            output, features = model.forward(target_x)\n",
    "\n",
    "            softmax_output = nn.Softmax(dim=1)(output)\n",
    "            entropy_loss = torch.mean(Entropy(softmax_output))\n",
    "\n",
    "            if model.margs.info_max:\n",
    "                msoftmax = softmax_output.mean(dim=0)\n",
    "                entropy_loss -= torch.sum(-msoftmax * torch.log(msoftmax + 1e-5))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            entropy_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print('Iter: %02d, Step: %02d/%02d' % (iter_num+1, i+1, len(dloaders['target_train'])), end='\\r')\n",
    "\n",
    "    model.save(source=False)\n",
    "\n",
    "def gen_path(path, name):\n",
    "    res = ''\n",
    "    path = osp.join(path, name)\n",
    "    for i, sub_forder in enumerate(sorted(os.listdir(path))):\n",
    "        for file in sorted(os.listdir(osp.join(path, sub_forder))):\n",
    "            res += osp.join(path, sub_forder, file) + ',%d\\n' % (i)\n",
    "\n",
    "    return res\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, margs, sargs):\n",
    "        self.F = network.ResBase(res_name='resnet50').cuda()\n",
    "        self.B = network.feat_bootleneck(type='bn', feature_dim=self.F.in_features, bottleneck_dim=256).cuda()\n",
    "        self.C = network.feat_classifier(type='wn', class_num=65, bottleneck_dim=256).cuda()\n",
    "        self.margs = margs\n",
    "        self.sargs = sargs\n",
    "    def save(self, source=True):\n",
    "        argstr = str({'source': margs.source}) if source else str(vars(margs))\n",
    "        path = osp.join(self.sargs.model_path, argstr)\n",
    "        os.mkdir(path)\n",
    "        torch.save(self.F.state_dict(), osp.join(path, 'F.pt'))\n",
    "        torch.save(self.B.state_dict(), osp.join(path, 'B.pt'))\n",
    "        torch.save(self.C.state_dict(), osp.join(path, 'C.pt'))\n",
    "    def load(self, source=True):\n",
    "        argstr = str({'source': margs.source}) if source else str(vars(margs))\n",
    "        path = osp.join(self.sargs.model_path, argstr)\n",
    "        self.F.load_state_dict(torch.load(osp.join(path, 'F.pt')))\n",
    "        self.B.load_state_dict(torch.load(osp.join(path, 'B.pt')))\n",
    "        self.C.load_state_dict(torch.load(osp.join(path, 'C.pt')))\n",
    "\n",
    "    def target_train_mode(self):\n",
    "        self.F.train()\n",
    "        self.B.train()\n",
    "        self.C.eval()\n",
    "\n",
    "    def train(self):\n",
    "        self.F.train()\n",
    "        self.B.train()\n",
    "        self.C.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.F.eval()\n",
    "        self.B.eval()\n",
    "        self.C.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.B(self.F(x))\n",
    "        return self.C(feature), feature\n",
    "\n",
    "    def copy(self, m):\n",
    "        self.F, self.B, self.C = m.F, m.B, m.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banner-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments_parsing():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    model = parser.add_argument_group('model')\n",
    "\n",
    "    model.add_argument('-im', '--info_max', action='store_true')\n",
    "    model.add_argument('-s', '--source', required=False, type=int, default=0)\n",
    "    model.add_argument('-t', '--target', required=False, type=int, default=1)\n",
    "\n",
    "    sys = parser.add_argument_group('sys')\n",
    "    sys.add_argument('-m', '--mode', choices=['source_train', 'target_train', 'target_test'], required=True)\n",
    "    sys.add_argument('-mp', '--model_path', default='./model/OfficeHome')\n",
    "    sys.add_argument('-dp', '--data_path', default='/tmp2/yc980802/da/data/OfficeHome')\n",
    "    sys.add_argument('-sm', '--source_model', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    model = Namespace(**{a.dest:args.__dict__[a.dest] for a in model._group_actions})\n",
    "    sys = Namespace(**{a.dest:args.__dict__[a.dest] for a in sys._group_actions})\n",
    "\n",
    "    return model, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handled-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Margs:\n",
    "    def __init__(self, im=False, s=0, t=1):\n",
    "        self.info_max=im\n",
    "        self.source=s\n",
    "        self.target=t\n",
    "class Sargs:\n",
    "    def __init__(self, m='target_test', mp='./model/OfficeHome', dp='/tmp2/yc980802/da/data/OfficeHome', sm=False):\n",
    "        self.mode=m\n",
    "        self.model_path=mp\n",
    "        self.data_path=dp\n",
    "        self.source_model=sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automatic-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.94%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    margs = Margs(im=False, s=0, t=2)\n",
    "    sargs = Sargs(dp='../data/OfficeHome')\n",
    "    names = ['Art', 'Clipart', 'Product', 'RealWorld']\n",
    "\n",
    "    class_num = 65\n",
    "    train_bs = 32\n",
    "\n",
    "    source_path = osp.join(sargs.data_path, names[margs.source] + '.txt')\n",
    "    target_path = osp.join(sargs.data_path, names[margs.target] + '.txt')\n",
    "\n",
    "    dsets, dloaders = load_data(source_path, target_path, train_bs)\n",
    "    model = Model(margs, sargs)\n",
    "\n",
    "    if sargs.mode == 'source_train':\n",
    "        source_train(dloaders, margs, sargs)\n",
    "    elif sargs.mode == 'target_train':\n",
    "        model.load(source=True)\n",
    "        target_train(dloaders, model)\n",
    "    else:\n",
    "        model.load(source=sargs.source_model)\n",
    "        print('Accuracy: %.2f%%' % (100*cal_acc(dloaders['target_test'], model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
